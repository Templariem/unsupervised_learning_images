# unsupervised_learning_images
Un recopilatorio de papers y técnicas de aprendizaje no supervisado aplicado a imágenes considerando:

1. K-means
2. Semantic search

| Title | Description | Tag | Date | Code |
|-------|-------------|-----|------|--------|
|[SCAN: Learning to Classify Images without Labels](https://arxiv.org/abs/2005.12320)|Can we automatically group images into semantically meaningful clusters when ground-truth annotations are absent? The task of unsupervised image classification remains an important, and open challenge in computer vision. Several recent approaches have tried to tackle this problem in an end-to-end fashion. In this paper, we deviate from recent works, and advocate a two-step approach where feature learning and clustering are decoupled. First, a self-supervised task from representation learning is employed to obtain semantically meaningful features. Second, we use the obtained features as a prior in a learnable clustering approach. In doing so, we remove the ability for cluster learning to depend on low-level features, which is present in current end-to-end learning approaches. Experimental evaluation shows that we outperform state-of-the-art methods by large margins, in particular +26.6% on CIFAR10, +25.0% on CIFAR100-20 and +21.3% on STL10 in terms of classification accuracy. Furthermore, our method is the first to perform well on a large-scale dataset for image classification. In particular, we obtain promising results on ImageNet, and outperform several semi-supervised learning methods in the low-data regime without the use of any ground-truth annotations.|Unsupervised Clasification|2020|[Github](https://github.com/wvangansbeke/Unsupervised-Classification)|
|[Semantic Image Segmentation: Two Decades of Research](https://arxiv.org/abs/2302.06378)|Semantic image segmentation (SiS) plays a fundamental role in a broad variety of computer vision applications, providing key information for the global understanding of an image. This survey is an effort to summarize two decades of research in the field of SiS, where we propose a literature review of solutions starting from early historical methods followed by an overview of more recent deep learning methods including the latest trend of using transformers. We complement the review by discussing particular cases of the weak supervision and side machine learning techniques that can be used to improve the semantic segmentation such as curriculum, incremental or self-supervised learning. State-of-the-art SiS models rely on a large amount of annotated samples, which are more expensive to obtain than labels for tasks such as image classification. Since unlabeled data is instead significantly cheaper to obtain, it is not surprising that Unsupervised Domain Adaptation (UDA) reached a broad success within the semantic segmentation community. Therefore, a second core contribution of this book is to summarize five years of a rapidly growing field, Domain Adaptation for Semantic Image Segmentation (DASiS) which embraces the importance of semantic segmentation itself and a critical need of adapting segmentation models to new environments. In addition to providing a comprehensive survey on DASiS techniques, we unveil also newer trends such as multi-domain learning, domain generalization, domain incremental learning, test-time adaptation and source-free domain adaptation. Finally, we conclude this survey by describing datasets and benchmarks most widely used in SiS and DASiS and briefly discuss related tasks such as instance and panoptic image segmentation, as well as applications such as medical image segmentation. | Semantic Segmentation | 2023 | - |
|[Few Shot Semantic Segmentation](https://github.com/xiaomengyc/Few-Shot-Semantic-Segmentation-Papers/blob/master/README.md)|Recopilatorio de papers asociados a la técnica de "Few Shot Semantic Segmentation" el cual consiste en entrenar un modelo no supervisado de segmentación considerando un conjunto menor de imagenes etiquetadas|Few Shot Semantic Segmentation|2017-2023| [Github](https://github.com/xiaomengyc/Few-Shot-Semantic-Segmentation-Papers/blob/master/README.md) |
|[Weakly Semantic Segmentation](https://github.com/PengtaoJiang/Awesome-Weakly-Supervised-Semantic-Segmentation-Papers)|Recopilatorio de papers asociados a "Weakly Semantic Segmentation" el cual consiste en entrenar un modelo de segmentación considerando una baja densidad de etiquetas por imagen|Weakly Semantic Segmentation|2017-2023| [Github](https://github.com/PengtaoJiang/Awesome-Weakly-Supervised-Semantic-Segmentation-Papers)|
|[Unsupervised Semantic Segmentation by Contrasting Object Mask Proposals](https://arxiv.org/pdf/2102.06191)|Being able to learn dense semantic representations of images without supervision is an important problem in com- puter vision. However, despite its significance, this problem remains rather unexplored, with a few exceptions that con- sidered unsupervised semantic segmentation on small-scale datasets with a narrow visual domain. In this paper, we make a first attempt to tackle the problem on datasets that have been traditionally utilized for the supervised case. To achieve this, we introduce a two-step framework that adopts a predetermined mid-level prior in a contrastive optimiza- tion objective to learn pixel embeddings. This marks a large deviation from existing works that relied on proxy tasks or end-to-end clustering. Additionally, we argue about the im- portance of having a prior that contains information about objects, or their parts, and discuss several possibilities to obtain such a prior in an unsupervised manner. Experimental evaluation shows that our method comes with key advantages over existing works. First, the learned pixel embeddings can be directly clustered in semantic groups using K-Means on PASCAL. Under the fully unsu- pervised setting, there is no precedent in solving the se- mantic segmentation task on such a challenging benchmark. Second, our representations can improve over strong base- lines when transferred to new datasets, e.g. COCO and DAVIS. The code is available.|Unsupervised Semantic Segmentation|2021|[Github](https://github.com/wvangansbeke/Unsupervised-Semantic-Segmentation)|
|[Segment Anything Model (SAM)](https://github.com/baibizhe/Awesome-SAM)|Recopilatorio de artículos con códigos de SAM en diversas tareas|Detections, Segmentations, Fine-tunning|-|[Github](https://github.com/baibizhe/Awesome-SAM)|
|[Unsupervised feature extraction of aerial images for clustering and understanding hazardous road segments](https://www.nature.com/articles/s41598-023-38100-1)|Aerial image data are becoming more widely available, and analysis techniques based on supervised learning are advancing their use in a wide variety of remote sensing contexts. However, supervised learning requires training datasets which are not always available or easy to construct with aerial imagery. In this respect, unsupervised machine learning techniques present important advantages. This work presents a novel pipeline to demonstrate how available aerial imagery can be used to better the provision of services related to the built environment, using the case study of road traffic collisions (RTCs) across three cities in the UK. In this paper, we show how aerial imagery can be leveraged to extract latent features of the built environment from the purely visual representation of top-down images. With these latent image features in hand to represent the urban structure, this work then demonstrates how hazardous road segments can be clustered to provide a data-augmented aid for road safety experts to enhance their nuanced understanding of how and where different types of RTCs occur.| Unsupervised Segmentation | 2023 | - |
|[Imagenes satelitales](https://github.com/satellite-image-deep-learning/techniques)| Recopilatorio de papers utilizando deep learning en imagenes satelitales en diversas tareas como detección, segmentación, analisis temporal, etc.| Imagenes satelitales | - | [Github](https://github.com/satellite-image-deep-learning/techniques) |
